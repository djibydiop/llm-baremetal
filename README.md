# ğŸš€ LLM Bare-Metal - Cognitive OS-Less Intelligence

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/djibydiop/llm-baremetal)
[![Version](https://img.shields.io/badge/version-8.0.0-blue.svg)](https://github.com/djibydiop/llm-baremetal/releases)
[![Platform](https://img.shields.io/badge/platform-UEFI%20x86--64-lightgrey.svg)](https://github.com/djibydiop/llm-baremetal)
[![Made in Senegal](https://img.shields.io/badge/Made%20in-Senegal%20ğŸ‡¸ğŸ‡³-green.svg)](https://github.com/djibydiop/llm-baremetal)

> **ğŸ”¥ World's ONLY bare-metal AI with DRC v6.0, CWEB Protocol, Multi-Format Support, and Chat REPL**

**Boot from USB. Chat with AI. Stream 100GB models. All without an OS.**

**ğŸ†• v8.0: DRC v6.0 (10 Phases) â€¢ CWEB Existence Protocol â€¢ ModelBridge Universal â€¢ Chat REPL â€¢ BIOO Vision**

---

## ğŸ¯ Revolutionary Features (World's ONLY)

### **DRC v6.0 - Cognitive Organism** ğŸ§ 
- **10 Cognitive Units**: URS, Verification, UIC, UCR, UTI, UCO, UMS, UAM, UPE, UIV
- **9 Infrastructure Systems**: Performance, Config, Trace, SelfDiag, SemanticCluster, TimeBudget, Bias, Emergency, RadioCognitive
- **Complete reasoning system** running bare-metal
- **No other firmware has cognitive capabilities**

### **CWEB - Cognitive Wireless Existence Boot** ğŸ“¡
- **"Systems don't boot. They decide to exist."**
- Progressive trust (5 levels: NONE â†’ IDENTITY â†’ CRYPTO â†’ BEHAVIORAL â†’ FULL)
- Distributed consensus (2/3 voting)
- Existence queries before every inference
- **Post-OS, post-BIOS, post-cloud architecture**

### **ModelBridge Universal** ğŸŒ‰
- **Auto-detects format**: GGUF, llama2.c .bin, SafeTensors, PyTorch
- **Zero-copy streaming**: Load 100GB models with 4MB chunks
- **Network streaming**: Bypass UEFI 512MB limit
- **Only universal model loader on bare-metal**

### **Chat REPL** ğŸ’¬
- **Interactive AI conversations** without OS
- Backspace support, command history
- Network boot for large models
- Commands: `/help`, `/history`, `/clear`, `/quit`

### **BIOO Vision** ğŸ”®
- **Future BIOS replacement**: Self-healing, cognitive, conversational
- Boot in <1 second
- No memory limits
- **The firmware that decides to exist**

---

## ğŸ¯ Features

### Core System
- âœ… **Network Boot** - Download models via HTTP (TCP4 protocol on UEFI)
- ğŸ“¡ **WiFi 6 Driver** - Intel AX200/AX201 bare-metal driver (Phase 1 complete)
- ğŸ§  **110M Model** - Stories110M (768 dims, 12 layers, 110M params, 418 MB)
- âœ… **UEFI Native** - Boots on any modern x86-64 hardware (2010+)
- âœ… **USB Bootable** - Flash to USB and boot instantly
- âœ… **SSE2 Optimized** - Hardware acceleration for matrix ops
- âœ… **BPE Tokenizer** - Full 32K vocabulary
- âœ… **DRC v4.0** - Djibion Reasoner Core

### Network Features (NEW!)
- ğŸŒ **HTTP Client** - Complete HTTP/1.0 implementation
- ğŸ“¥ **Model Download** - Stream models from remote server
- ğŸ”„ **Hybrid Boot** - Network â†’ Disk fallback
- ğŸ“¡ **WiFi 6** - Intel AX200 driver (in development)
- ğŸ” **WPA2** - Secure WiFi (roadmap)

### Technical Specs
- ğŸ§  **Models**: Stories15M (60 MB) + Stories110M (418 MB)
- âš¡ **Speed**: ~12 tokens/sec on modern hardware
- ğŸŒ **Network**: TCP4 + HTTP/1.0 + WiFi 6 (Phase 1)
- ğŸ”§ **Platform**: UEFI x86_64 (GNU-EFI 3.0+)
- ğŸ’¾ **Memory**: 1024 MB RAM (for 110M model)
- ğŸ“¦ **Total Size**: 420 MB (model + tokenizer + code)

---

## ğŸš€ Quick Start (3 Commands)

## ğŸš€ Quick Start

### Method 1: Test in QEMU (Fastest)

```bash
# Linux/WSL
git clone https://github.com/djibydiop/llm-baremetal.git
cd llm-baremetal
./download_stories110m.sh  # Downloads stories15M.bin
make && make disk
qemu-system-x86_64 -bios /usr/share/ovmf/OVMF.fd -drive file=qemu-test.img,format=raw -m 512
```

```powershell
# Windows (native QEMU)
git clone https://github.com/djibydiop/llm-baremetal.git
cd llm-baremetal
wsl bash -c './download_stories110m.sh && make && make disk'
& 'C:\Program Files\qemu\qemu-system-x86_64.exe' -bios OVMF.fd -drive file=qemu-test.img,format=raw -m 512
```

### Method 2: Boot on Real Hardware

1. **Download**: Get `llm-baremetal-usb.img` from [Releases](https://github.com/djibydiop/llm-baremetal/releases)
2. **Flash**: Use [Rufus](https://rufus.ie/) (Windows) or `dd` (Linux)
   - Mode: DD Image
   - Partition scheme: GPT
   - Target system: UEFI (not CSM)
3. **Boot**: Insert USB, restart PC, press F12/F2, select USB
4. **Watch**: AI boots and generates text in 5-10 seconds!

---

## ğŸ“– What You'll See

```
========================================================
        B A R E - M E T A L   N E U R A L   L L M
========================================================
  Transformer 15M | 6 layers x 288 dimensions
  Powered by DRC v4.0 (Djibion Reasoner Core)
  Made in Senegal by Djiby Diop
========================================================

  Loading stories15M.bin (60 MB)...
  Progress: 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Done!
  Model loaded successfully!

  Loading BPE tokenizer...
  [SUCCESS] Tokenizer loaded (32000 tokens)

  Model: Stories15M (288 dim, 6 layers, 15M params)
  Sampling: Temperature 1.2 | Steps: 150

  === Story Generation ===

  Assistant: Once upon a time, there was a little girl named Lily...
  [text continues for 150 tokens]

  ========================================
  Generation Complete!
  ========================================
```

---

## ğŸ› ï¸ Technical Architecture

### Model Pipeline
1. **UEFI Boot** â†’ Firmware initializes hardware
2. **Load Model** â†’ 60 MB stories15M.bin loaded into memory
3. **Load Tokenizer** â†’ 32K vocab SentencePiece BPE
4. **Initialize DRC** â†’ Djibion Reasoner Core v4.0
5. **Generate** â†’ 150 tokens via transformer forward passes
6. **Display** â†’ Real-time text output on screen

### Core Components
- **llama2_efi.c** (8491 lines): Main transformer implementation
  - Self-attention with RoPE positional encoding
  - SwiGLU activation functions
  - RMSNorm normalization
  - KV-cache for efficiency
- **DRC v4.0**: Neural optimization layer
  - Domain detection
  - Logit stabilization
  - Diversity forcing
  - Stagnation prevention
- **Tokenizer**: SentencePiece BPE decoder
- **Math**: Optimized softmax, matmul, RoPE (SSE2)

### Why No Colors?
Initial version had color UI, but `SetAttribute()` UEFI calls caused system freezes on some firmware. Current version uses plain white text for **maximum hardware compatibility**.
- 17 NEURO-NET algorithms to study
- Benchmarking tools

---

## ğŸ¬ See It In Action

---

## ğŸ”§ Building from Source

### Prerequisites
- x86-64 PC (2010 or newer)
- WSL2 (Windows) or Linux
- gcc, gnu-efi, qemu
- 4GB+ RAM
- USB stick (128MB+) for real hardware testing

### Build Steps

```bash
# 1. Install dependencies (Ubuntu/Debian)
sudo apt update
sudo apt install build-essential gnu-efi qemu-system-x86 mtools dosfstools

# 2. Clone repository
git clone https://github.com/djibydiop/llm-baremetal.git
cd llm-baremetal

# 3. Download model (60 MB)
./download_stories110m.sh
# This downloads stories15M.bin from HuggingFace

# 4. Download tokenizer
wget https://github.com/karpathy/llama2.c/raw/master/tokenizer.bin

# 5. Build
make clean && make

# 6. Create bootable disk image
make disk
# Creates qemu-test.img (128 MB) with EFI + model + tokenizer

# 7. Test in QEMU
qemu-system-x86_64 -bios /usr/share/ovmf/OVMF.fd -drive file=qemu-test.img,format=raw -m 512

# 8. Create USB image (optional)
cp qemu-test.img llm-baremetal-usb.img
# Flash this to USB with Rufus (Windows) or dd (Linux)
```

### Windows-Specific (PowerShell)

```powershell
# Install WSL2 if not already installed
wsl --install -d Ubuntu

# Build inside WSL
wsl bash -c 'cd /mnt/c/Users/YOUR_USER/Desktop/llm-baremetal && make && make disk'

# Test with Windows QEMU (much faster than WSL QEMU)
& 'C:\Program Files\qemu\qemu-system-x86_64.exe' -bios OVMF.fd -drive file=qemu-test.img,format=raw -m 512
```

---

## ï¿½ Project Stats

- **Lines of Code**: 8,491 (main transformer) + tokenizer + math libs
- **Model Size**: 60 MB (stories15M.bin)
- **Vocabulary**: 32,000 tokens (SentencePiece BPE)
- **Architecture**: 6 layers, 288 dimensions, 6 attention heads
- **Parameters**: 15 million
- **Inference Speed**: ~12 tokens/second (modern hardware)
- **Boot Time**: 5-10 seconds (USB to text generation)

---

## ğŸ¯ Roadmap

### âœ… v6.0 (Current - December 2025)
- âœ… Full Stories15M (60MB) working on real hardware
- âœ… USB bootable image creation
- âœ… DRC v4.0 neural optimization
- âœ… Hardware compatibility (removed SetAttribute freezes)
- âœ… Production ready

### ğŸš§ v6.1 (Next - Q1 2026)
- **Larger Models** - 110M, 260M parameter support
- **Quantization** - 4-bit/8-bit inference for bigger models
- **ARM64 Port** - Raspberry Pi 4/5 support
- **Network Boot** - PXE/HTTP model loading
- **Multi-GPU** - Distributed inference across machines

### ğŸ”® v7.0 (Future)
- **LLaMA 3 Support** - Full 8B models
- **LoRA Adapters** - Fine-tuning support
- **Voice I/O** - Audio input/output
- **Multimodal** - Image understanding (CLIP integration)
- Multi-modal (text + images)
- GPU acceleration (Vulkan)
- Phase 5 NEURO-NET (5 new features)
- Real-time fine-tuning

**â†’** [Full roadmap](ROADMAP.md)

---

## ğŸ“Š Performance

| Metric | stories15M | stories110M |
|--------|-----------|-------------|
| Binary Size | 157 KB | 157 KB |
| Model Size | 60 MB | 420 MB |
| Boot Time | ~2 sec | ~3 sec |
| Load Time | ~1 sec | ~5 sec |
| Tokens/sec | ~80 | ~50 |
| Memory Usage | 512 MB | 1.2 GB |

*Tested on Intel i5-8250U, 8GB RAM, USB 3.0*

---

## ğŸš€ Hardware Requirements

### Minimum
- x86-64 CPU with AVX2 support (Intel Haswell 2013+, AMD Excavator 2015+)
- 4GB RAM
- UEFI firmware
- USB 2.0+ (for USB boot)

### Recommended
- Intel Core i5/i7 (4th gen+) or AMD Ryzen
- 8GB RAM
- USB 3.0+

### BIOS Settings
- **UEFI boot mode** (not Legacy/CSM)
- **Secure Boot disabled**
- **Fast Boot disabled** (optional, helps with debugging)

---

## ğŸ› Troubleshooting

### Boot stops at "127580KB read"
**Solution:** Model file too large for your UEFI firmware. Use `stories15M.bin` (60MB) instead of `stories110M.bin` (420MB).

### "No bootable device" error
**Solution:** 
1. Ensure USB is FAT32 formatted
2. Check UEFI boot mode (not Legacy)
3. Disable Secure Boot in BIOS

### "AVX2 not supported" error
**Solution:** Your CPU doesn't support AVX2. Minimum requirement is Intel Haswell (2013) or AMD Excavator (2015).

### Slow inference (< 10 tokens/sec)
**Solution:**
1. Enable AVX2 in BIOS (if available)
2. Use smaller model (stories15M vs stories110M)
3. Increase RAM allocation in QEMU/VM

---

## ï¿½ Documentation

| Document | Description |
|----------|-------------|
| [USB_BOOT_GUIDE.md](USB_BOOT_GUIDE.md) | How to flash and boot from USB |
| [HARDWARE_BOOT.md](HARDWARE_BOOT.md) | Hardware compatibility notes |
| [ROADMAP.md](ROADMAP.md) | Development roadmap |
| [llama2_efi.c](llama2_efi.c) | Main source code (8,491 lines) |

---

## â“ FAQ

**Q: Why bare-metal? Why not just run on Linux?**  
A: Zero OS overhead = faster boot, simpler debugging, perfect for embedded systems, and it's just **way cooler** ğŸ˜

**Q: Can I use bigger models?**  
A: Currently optimized for 15M-110M params. Larger models (8B+) need quantization or more RAM.

**Q: Does it work on my PC?**  
A: Any x86-64 PC from 2010+ with UEFI should work. Tested on Dell, HP, Lenovo, custom builds.

**Q: How fast is it?**  
A: ~12 tokens/sec on modern hardware. Boot to text generation in 5-10 seconds.

**Q: Can I train models with this?**  
A: No, this is inference only. Use PyTorch/JAX for training, then load the weights here.

**Q: Why is there no color in the output?**  
A: UEFI's `SetAttribute()` caused system freezes on some firmware. Plain text = maximum compatibility.

**Q: Is this production-ready?**  
A: Yes! Tested on real hardware. Use at your own risk, but it's stable.

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

1. **Star the repo** â­ if you find it useful
2. **Fork** and create a feature branch
3. **Add your use case** to examples/
4. **Submit a PR** with improvements
5. **Share** with the community

**Areas we need help:**
- LLaMA 3 integration
- ARM64 port
- Performance optimizations
- More examples
- Documentation improvements

---

## ğŸ¤ Contributing

Contributions welcome! Areas needing help:
- ARM64 port (Raspberry Pi)
- Larger model support (quantization)
- Performance optimizations
- Testing on more hardware

1. Fork the repo â†’ 2. Create feature branch â†’ 3. Submit PR

---

## ğŸ“œ License

**MIT License** - See [LICENSE](LICENSE)

**Credits:**
- **llama2.c** by Andrej Karpathy - Base transformer implementation
- **GNU-EFI** - UEFI development library  
- **DRC v4.0** - Djibion Reasoner Core (original innovation)
- **Optimized math** - Justine Tunney's powf implementation

---

## ğŸ™ Acknowledgments

- **Andrej Karpathy** (@karpathy) - For llama2.c and making AI education accessible
- **The UEFI community** - For excellent documentation and tools
- **TinyStories dataset** - For training the Stories15M model
- **Everyone who tested** - Your feedback made this production-ready

---

## ğŸŒ Made in Senegal ğŸ‡¸ğŸ‡³

Created in Dakar, Senegal. Pushing African tech innovation to the world.

---

## ğŸ”— Connect & Share

- ğŸ™ **GitHub**: https://github.com/djibydiop/llm-baremetal
- ğŸ› **Issues**: [Report bugs](https://github.com/djibydiop/llm-baremetal/issues)
- ğŸ¦ **Twitter/X**: [#LLMBareMetal](https://twitter.com/search?q=%23LLMBareMetal) [#BareMetalAI](https://twitter.com/search?q=%23BareMetalAI)
- ğŸ¥ **Demo Video**: _(Add your video link here)_

---

<div align="center">

### â­ Star this repo if it amazed you! â­

**World's First Bare-Metal LLM â€¢ Made with â¤ï¸ in Senegal ğŸ‡¸ğŸ‡³**

_Boot AI in 5 seconds. No OS required. Just pure innovation._

</div>

---

## âš ï¸ Important Notes

1. **Model files NOT included** - Download `stories15M.bin` (60MB) and `tokenizer.bin` via `download_stories110m.sh`
2. **UEFI only** - Does not work with Legacy BIOS mode
3. **Hardware requirements** - x86-64 CPU (2010+), 512MB+ RAM, UEFI firmware
4. **No colors** - Plain text for maximum compatibility (SetAttribute causes freezes on some firmware)

---

**Last Updated:** December 14, 2025  
**Version:** 6.0.0 (Production Ready)
